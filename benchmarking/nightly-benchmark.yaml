# These two paths must be defined and are used to resolve the results and
# datasets paths. These must be existing paths on the host.
# If running inside a Docker container started with tools/run.sh, the paths
# will automatically be mapped to the appropriate volume mount.
# If running on the host, the paths will remain as defined below.
# Paths can be used in other values in this file by using their placeholder
# (e.g. {datasets_path}/my/test/dataset.parquet) and will be resolved to the
# appropriate path at runtime.
results_path: /path/where/results/are/stored
datasets_path: /path/to/datasets

datasets:
  - name: "tinystories"
    formats:
    - type: "parquet"
      path: "{datasets_path}/tinystories/parquet_data"
    - type: "jsonl"
      path: "{datasets_path}/tinystories/jsonl_data"
  - name: "commoncrawl"
    formats:
    - type: "jsonl"
      path: "{datasets_path}/commoncrawl/jsonl_data"
  - name: "commoncrawl_id_map"
    formats:
    - type: "json"
      path: "{datasets_path}/commoncrawl/id_generator.json"
  - name: "commoncrawl_ids"
    formats:
    - type: "parquet"
      path: "{datasets_path}/commoncrawl/IDs/parquet_data"


default_timeout_s: 7200

# Optional sinks
sinks:
#  - name: mlflow
#    enabled: false
#    tracking_uri: ${MLFLOW_TRACKING_URI}
#    experiment: ray-curator-common-crawl
  - name: slack
    enabled: true
    webhook_url: ${SLACK_WEBHOOK_URL}
    default_metrics: ["exec_time_s"]
#  - name: gdrive
#    enabled: false
#    drive_folder_id: ${GDRIVE_FOLDER_ID}
#    service_account_file: ${GDRIVE_SERVICE_ACCOUNT_FILE}

# Whether to delete scratch dirs after each run
delete_scratch: true

entries:
  - name: domain_classification_raydata
    enabled: true
    script: domain_classification_benchmark.py
    args: >-
      --benchmark-results-path={session_entry_dir}
      --executor=ray_data
      --input-path={dataset:tinystories,parquet}
      --dataset-size-gb=10
      --model-inference-batch-size=1024
    timeout_s: 20000
    sink_data:
      - name: slack
        # Additional metrics to include in the Slack report.  These must be present in the metrics.json file generated by the script.
        additional_metrics: ["num_documents_processed", "throughput_docs_per_sec"]
    ray:
      num_cpus: 64
      num_gpus: 4
      enable_object_spilling: false
    # Additional requirements for the benchmark to pass.  These will result in the benchmark being marked as failed if not met.
    requirements:
      - metric: throughput_docs_per_sec
        min_value: 0.2

  - name: domain_classification_xenna
    enabled: true
    script: domain_classification_benchmark.py
    args: >-
      --benchmark-results-path={session_entry_dir}
      --executor=xenna
      --input-path={dataset:tinystories,parquet}
      --dataset-size-gb=10
      --model-inference-batch-size=1024
    timeout_s: 20000

  - name: embedding_generation_raydata
    enabled: true
    script: embedding_generation_benchmark.py
    args: >-
      --benchmark-results-path={session_entry_dir}
      --executor=ray_data
      --input-path={dataset:tinystories,parquet}
      --dataset-size-gb=10
      --model-identifier=sentence-transformers/all-MiniLM-L6-v2
      --model-inference-batch-size=1024
    timeout_s: 20000
    sink_data:
      - name: slack
        additional_metrics: ["num_documents_processed", "throughput_docs_per_sec"]
    ray:
      num_cpus: 64
      num_gpus: 4
      enable_object_spilling: false

  - name: embedding_generation_xenna
    enabled: true
    script: embedding_generation_benchmark.py
    args: >-
      --benchmark-results-path={session_entry_dir}
      --executor=xenna
      --input-path={dataset:tinystories,parquet}
      --dataset-size-gb=10
      --model-identifier=sentence-transformers/all-MiniLM-L6-v2
      --model-inference-batch-size=1024
    timeout_s: 20000

  - name: fuzzy_dedup_identification
    enabled: true
    script: fuzzy_dedup_identification_benchmark.py
    args: >-
      --benchmark-results-path={session_entry_dir}
      --input-path={dataset:commoncrawl,jsonl}
      --cache-path={session_entry_dir}/scratch/cache
      --output-path={session_entry_dir}/output
      --input-filetype=jsonl
      --bands-per-iteration=20
      --text-field=text
      --input-blocksize=1.5GiB
    timeout_s: 20000
    ray:
      num_cpus: 64
      num_gpus: 4
      enable_object_spilling: false

  - name: dedup_removal_raydata
    enabled: true
    script: dedup_removal_benchmark.py
    args: >-
      --benchmark-results-path={session_entry_dir}
      --input-path={dataset:commoncrawl,jsonl}
      --id-generator-path={dataset:commoncrawl_id_map,json}
      --ids-to-remove-path={dataset:commoncrawl_ids,parquet}
      --output-path={session_entry_dir}/scratch/output
      --executor=ray_data
      --input-filetype=jsonl
      --output-filetype=parquet
      --id-field=_curator_dedup_id
      --duplicate-id-field=_curator_dedup_id
      --blocksize=1.5GiB
    timeout_s: 20000
    ray:
      num_cpus: 64
      num_gpus: 4
      enable_object_spilling: false

  - name: dedup_removal_xenna
    enabled: true
    script: dedup_removal_benchmark.py
    args: >-
      --benchmark-results-path={session_entry_dir}
      --input-path={dataset:commoncrawl,jsonl}
      --id-generator-path={dataset:commoncrawl_id_map,json}
      --ids-to-remove-path={dataset:commoncrawl_ids,parquet}
      --output-path={session_entry_dir}/scratch/output
      --executor=xenna
      --input-filetype=jsonl
      --output-filetype=parquet
      --id-field=_curator_dedup_id
      --duplicate-id-field=_curator_dedup_id
      --blocksize=1.5GiB
    timeout_s: 20000
