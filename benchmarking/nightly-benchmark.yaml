# These two paths must be defined and are used to resolve the results and
# datasets paths. These must be existing paths on the host.
# If running inside a Docker container started with tools/run.sh, the paths
# will automatically be mapped to the appropriate volume mount.
# If running on the host, the paths will remain as defined below.
# Paths can be used in other values in this file by using their placeholder
# (e.g. {datasets_path}/my/test/dataset.parquet) and will be resolved to the
# appropriate path at runtime.
results_path: /path/where/results/are/stored
datasets_path: /path/to/datasets

datasets:
  - name: "tinystories"
    formats:
    - type: "parquet"
      path: "{datasets_path}/tinystories/parquet_data"
    - type: "jsonl"
      path: "{datasets_path}/tinystories/jsonl_data"
  - name: "commoncrawl"
    formats:
    - type: "jsonl"
      path: "{datasets_path}/commoncrawl/jsonl_data"
  - name: "commoncrawl_id_map"
    formats:
    - type: "json"
      path: "{datasets_path}/commoncrawl/id_generator.json"
  - name: "commoncrawl_ids"
    formats:
    - type: "parquet"
      path: "{datasets_path}/commoncrawl/IDs/parquet_data"
  - name: "mscoco"
    formats:
    - type: "wds"
      path: "{datasets_path}/mscoco/wds/truncated_100K_mscoco_benchmarking"
  - name: "mscoco_model_weights"
    formats:
    - type: "files"
      path: "{datasets_path}/mscoco/model_weights"
  - name: "rpv1"
    formats:
    - type: parquet"
    - path: "{datasets_path}/rpv1_consistent_schema/parquet"

default_timeout_s: 7200

# Optional sinks
sinks:
#  - name: mlflow
#    enabled: false
#    tracking_uri: ${MLFLOW_TRACKING_URI}
#    experiment: ray-curator-common-crawl
  - name: slack
    enabled: true
    webhook_url: ${SLACK_WEBHOOK_URL}
    default_metrics: ["exec_time_s"]
#  - name: gdrive
#    enabled: false
#    drive_folder_id: ${GDRIVE_FOLDER_ID}
#    service_account_file: ${GDRIVE_SERVICE_ACCOUNT_FILE}

# Whether to delete scratch dirs after each run
delete_scratch: true

entries:
  - name: domain_classification_raydata
    enabled: true
    script: domain_classification_benchmark.py
    args: >-
      --benchmark-results-path={session_entry_dir}
      --executor=ray_data
      --input-path={dataset:tinystories,parquet}
      --dataset-size-gb=10
      --model-inference-batch-size=1024
    timeout_s: 20000
    sink_data:
      - name: slack
        # Additional metrics to include in the Slack report.  These must be present in the metrics.json file generated by the script.
        additional_metrics: ["num_documents_processed", "throughput_docs_per_sec"]
    ray:
      num_cpus: 64
      num_gpus: 4
      enable_object_spilling: false
    # Additional requirements for the benchmark to pass.  These will result in the benchmark being marked as failed if not met.
    requirements:
      - metric: throughput_docs_per_sec
        min_value: 0.2

  - name: domain_classification_xenna
    enabled: true
    script: domain_classification_benchmark.py
    args: >-
      --benchmark-results-path={session_entry_dir}
      --executor=xenna
      --input-path={dataset:tinystories,parquet}
      --dataset-size-gb=10
      --model-inference-batch-size=1024
    timeout_s: 20000

  - name: embedding_generation_raydata
    enabled: true
    script: embedding_generation_benchmark.py
    args: >-
      --benchmark-results-path={session_entry_dir}
      --executor=ray_data
      --input-path={dataset:tinystories,parquet}
      --dataset-size-gb=10
      --model-identifier=sentence-transformers/all-MiniLM-L6-v2
      --model-inference-batch-size=1024
    timeout_s: 20000
    sink_data:
      - name: slack
        additional_metrics: ["num_documents_processed", "throughput_docs_per_sec"]
    ray:
      num_cpus: 64
      num_gpus: 4
      enable_object_spilling: false

  - name: embedding_generation_xenna
    enabled: true
    script: embedding_generation_benchmark.py
    args: >-
      --benchmark-results-path={session_entry_dir}
      --executor=xenna
      --input-path={dataset:tinystories,parquet}
      --dataset-size-gb=10
      --model-identifier=sentence-transformers/all-MiniLM-L6-v2
      --model-inference-batch-size=1024
    timeout_s: 20000

  - name: fuzzy_dedup_identification
    enabled: true
    script: fuzzy_dedup_identification_benchmark.py
    args: >-
      --benchmark-results-path={session_entry_dir}
      --input-path={dataset:commoncrawl,jsonl}
      --cache-path={session_entry_dir}/scratch/cache
      --output-path={session_entry_dir}/output
      --input-filetype=jsonl
      --bands-per-iteration=20
      --text-field=text
      --input-blocksize=1.5GiB
    timeout_s: 20000
    ray:
      num_cpus: 64
      num_gpus: 4
      enable_object_spilling: false

  - name: exact_dedup_identification
    enabled: true
    script: exact_dedup_identification_benchmark.py
    args: >-
      --benchmark-results-path={session_entry_dir}
      --input-path={dataset:commoncrawl,jsonl}
      --output-path={session_entry_dir}/output
      --input-filetype=jsonl
      --text-field=text
      --input-blocksize=2GiB
    timeout_s: 20000
    sink_data:
      - name: slack
        additional_metrics: ["num_duplicates_identified", "identification_time_s"]
    ray:
      num_cpus: 64
      num_gpus: 4
      enable_object_spilling: false

  - name: dedup_removal_raydata
    enabled: true
    script: dedup_removal_benchmark.py
    args: >-
      --benchmark-results-path={session_entry_dir}
      --input-path={dataset:commoncrawl,jsonl}
      --id-generator-path={dataset:commoncrawl_id_map,json}
      --ids-to-remove-path={dataset:commoncrawl_ids,parquet}
      --output-path={session_entry_dir}/scratch/output
      --executor=ray_data
      --input-filetype=jsonl
      --output-filetype=parquet
      --id-field=_curator_dedup_id
      --duplicate-id-field=_curator_dedup_id
      --blocksize=1.5GiB
    timeout_s: 20000
    ray:
      num_cpus: 64
      num_gpus: 4
      enable_object_spilling: false

  - name: dedup_removal_xenna
    enabled: true
    script: dedup_removal_benchmark.py
    args: >-
      --benchmark-results-path={session_entry_dir}
      --input-path={dataset:commoncrawl,jsonl}
      --id-generator-path={dataset:commoncrawl_id_map,json}
      --ids-to-remove-path={dataset:commoncrawl_ids,parquet}
      --output-path={session_entry_dir}/scratch/output
      --executor=xenna
      --input-filetype=jsonl
      --output-filetype=parquet
      --id-field=_curator_dedup_id
      --duplicate-id-field=_curator_dedup_id
      --blocksize=1.5GiB
    timeout_s: 20000

  - name: score_filter_raydata
    enabled: true
    script: score_filter_benchmark.py
    args: >-
      --benchmark-results-path={session_entry_dir}
      --executor=ray_data
      --input-path={dataset:tinystories,parquet}
      --yaml-config={curator_repo_dir}/nemo_curator/config/text/heuristic_filter_english_pipeline.yaml
      --overrides="stages.0._target_=nemo_curator.stages.text.io.reader.ParquetReader"
    timeout_s: 20000
    ray:
      num_cpus: 64
      num_gpus: 0
      enable_object_spilling: false

  - name: score_filter_xenna
    enabled: true
    script: score_filter_benchmark.py
    args: >-
      --benchmark-results-path={session_entry_dir}
      --executor=xenna
      --input-path={dataset:tinystories,parquet}
      --yaml-config={curator_repo_dir}/nemo_curator/config/text/heuristic_filter_english_pipeline.yaml
      --overrides="stages.0._target_=nemo_curator.stages.text.io.reader.ParquetReader"
    timeout_s: 20000
    ray:
      num_cpus: 64
      num_gpus: 0
      enable_object_spilling: false

  - name: image_curation
    enabled: true
    script: "{curator_repo_dir}/tutorials/image/getting-started/image_curation_example.py"
    args: >-
      --input-wds-dataset-dir {dataset:mscoco,wds}
      --output-dataset-dir {session_entry_dir}/results_truncated_100K_mscoco
      --model-dir {dataset:mscoco_model_weights,files}
      --batch-size 100
      --embedding-batch-size 100
      --aesthetic-batch-size 100
      --nsfw-batch-size 100
      --tar-files-per-partition 10
      --aesthetic-threshold 0.9
      --nsfw-threshold 0.9
      --skip-download
      --verbose

  - name: audio_fleurs
    enabled: true
    script: audio_fleurs_benchmark.py
    args: >-
      --benchmark-results-path={session_entry_dir}
      --scratch-output-path={session_entry_dir}/scratch
      --model-name=nvidia/stt_hy_fastconformer_hybrid_large_pc
      --lang=hy_am
      --split=dev
      --wer-threshold=5.5
      --gpus=1
